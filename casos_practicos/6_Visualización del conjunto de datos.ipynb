{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1FeU5dUwyPAto4Sc9jBli5Pu1duIQX7hp\">Abre este Jupyter en Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se muestran algunos de los mecanismos más utilizados para la visualización del conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción\n",
    "NSL-KDD is a data set suggested to solve some of the inherent problems of the KDD'99 data set which are mentioned in. Although, this new version of the KDD data set still suffers from some of the problems discussed by McHugh and may not be a perfect representative of existing real networks, because of the lack of public data sets for network-based IDSs, we believe it still can be applied as an effective benchmark data set to help researchers compare different intrusion detection methods. Furthermore, the number of records in the NSL-KDD train and test sets are reasonable. This advantage makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research work will be consistent and comparable.\n",
    "\n",
    "### Ficheros de datos\n",
    "* <span style=\"color:green\">**KDDTrain+.ARFF**: The full NSL-KDD train set with binary labels in ARFF format</span>\n",
    "* <span style=\"color:green\">**KDDTrain+.TXT**: The full NSL-KDD train set including attack-type labels and difficulty level in CSV format</span>\n",
    "* KDDTrain+_20Percent.ARFF:\tA 20% subset of the KDDTrain+.arff file\n",
    "* KDDTrain+_20Percent.TXT:\tA 20% subset of the KDDTrain+.txt file\n",
    "* KDDTest+.ARFF:\tThe full NSL-KDD test set with binary labels in ARFF format\n",
    "* KDDTest+.TXT:\tThe full NSL-KDD test set including attack-type labels and difficulty level in CSV format\n",
    "* KDDTest-21.ARFF:\tA subset of the KDDTest+.arff file which does not include records with difficulty level of 21 out of 21\n",
    "* KDDTest-21.TXT:\tA subset of the KDDTest+.txt file which does not include records with difficulty level of 21 out of 21\n",
    "\n",
    "### Descarga de los ficheros de datos\n",
    "https://iscxdownloads.cs.unb.ca/iscxdownloads/NSL-KDD/#NSL-KDD\n",
    "\n",
    "### Referencias adicionales sobre el conjunto de datos\n",
    "_M. Tavallaee, E. Bagheri, W. Lu, and A. Ghorbani, “A Detailed Analysis of the KDD CUP 99 Data Set,” Submitted to Second IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA), 2009._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lectura del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del conjunto de datos mediante funciones de Python\n",
    "with open(\"datasets/NSL-KDD/KDDTrain+.txt\") as train_set:\n",
    "    df = train_set.readlines()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del conjunto de datos utilizando Pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/NSL-KDD/KDDTrain+.txt\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los ficheros en el directorio del conjunto de datos\n",
    "import os\n",
    "\n",
    "os.listdir(\"datasets/NSL-KDD/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **ARFF (Attribute-Relation File Format)** file is an ASCII text file that describes a list of instances sharing a set of attributes. ARFF files were developed by the Machine Learning Project at the Department of Computer Science of The University of Waikato for use with the Weka machine learning software. Más información: https://www.cs.waikato.ac.nz/ml/weka/arff.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos un nuevo paquete externo para poder leer ficheros arff\n",
    "!pip install liac-arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del conjunto de datos que se encuentra en formato .arff\n",
    "import arff\n",
    "\n",
    "with open('datasets/NSL-KDD/KDDTrain+.arff', 'r') as train_set:\n",
    "    df = arff.load(train_set)\n",
    "\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"attributes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parseamos los atributos para obtener únicamente los nombres\n",
    "atributos = [attr[0] for attr in df[\"attributes\"]]\n",
    "atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el conjunto de datos con Pandas para facilitar la manipulación\n",
    "df = pd.DataFrame(df[\"data\"], columns=atributos)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llegados a este punto lo ideal es construir una función que permita leer el conjunto de datos de manera más limpia. Este tipo de prácticas son de gran utilidad para que nuestro código en el Jupyter Notebook sea más modular y pueda reutilizarse de manera más sencilla para futuros ejercicios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kdd_dataset(data_path):\n",
    "    \"\"\"Lectura del conjunto de datos NSL-KDD.\"\"\"\n",
    "    with open(data_path, 'r') as train_set:\n",
    "        dataset = arff.load(train_set)\n",
    "    attributes = [attr[0] for attr in dataset[\"attributes\"]]\n",
    "    return pd.DataFrame(dataset[\"data\"], columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_kdd_dataset('datasets/NSL-KDD/KDDTrain+.arff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Funciones básicas de visualización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El proceso de visualización siempre debe realizarse sobre el trainning set y apartando el test set. Esto evita que nuestro cerebro genere intuiciones del test set que podemos incorporar en nuestro modelo\n",
    "* Una buena práctica es crear una copia del trainning set y jugar con ella. De esta manera, si realizamos transformaciones que dañan el tranning set, el original no se ve afectado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura y copia del conjunto de datos\n",
    "df_orig = load_kdd_dataset('datasets/NSL-KDD/KDDTrain+.arff')\n",
    "df = df_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar en pantalla un número determinado de filas\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar información básica sobre el conjunto de datos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar información estadística sobre el conjunto de datos\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los valores únicos que tiene un atributo determinado\n",
    "df[\"protocol_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los valores de la característica como un histograma\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "df[\"protocol_type\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representar gráficamente la distribución de los atributos\n",
    "df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funciones avanzadas de visualización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando correlaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se puede calcular el coeficiente de correlación estándar para ver la correlación entre cada par de atributos\n",
    "* El coeficiente de correlación, solo mide **correlaciones lineales**, esto quiere decir que si x va hacia arriba, mediría si y va hacia arriba o hacia abajo.\n",
    "* **Hay que intentar buscar correlaciones sobre todo con el atributo objetivo (el que queremeos predecir), en este caso _class_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El atributo class de nuestro conjunto de datos tiene valores categoricos\n",
    "df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Transformamos los valores del atributo class de categoricos a numéricos\n",
    "labelencoder = LabelEncoder()\n",
    "df[\"class\"] = labelencoder.fit_transform(df[\"class\"])\n",
    "\n",
    "# Transformamos los valores de los atributos categóricos a numéricos\n",
    "df[\"protocol_type\"] = labelencoder.fit_transform(df[\"protocol_type\"])\n",
    "df[\"service\"] = labelencoder.fit_transform(df[\"service\"])\n",
    "df[\"flag\"] = labelencoder.fit_transform(df[\"flag\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la correlación entre los atributos del conjunto de datos\n",
    "corr_matrix = df.corr()\n",
    "corr_matrix[\"class\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar correlación lineal entre todos los atributos del conjunto de datos\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representar gráficamente la matriz de correlación\n",
    "corr = df.corr()\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(corr)\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "plt.yticks(range(len(corr.columns)), corr.columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representar gráficamente las correlaciones\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"same_srv_rate\", \"dst_host_srv_count\", \"class\", \"dst_host_same_srv_rate\"]\n",
    "\n",
    "scatter_matrix(df[attributes], figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
